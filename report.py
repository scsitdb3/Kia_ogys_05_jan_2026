def process_files(validation_errors, all_locations, start_date, end_date, total_locations,
                  progress_bar, status_text, select_categories):

    import streamlit as st
    import os
    import io
    import zipfile
    import pandas as pd
    from datetime import datetime, timedelta
    from collections import defaultdict

    # Keep DataFrame previews separate from downloadable file bytes
    previews = {}  # name -> DataFrame
    files = {}     # name -> excel bytes

    # ---------- helpers ----------
    def read_file(file_path,header=None):
      if "extracted_files/" in file_path:
          file_name = file_path.split("extracted_files/", 1)[1]
      else:
          file_name = os.path.basename(file_path)
      try:
          if file_path.lower().endswith('.xlsx'):
              return pd.read_excel(file_path, header=header, engine='openpyxl')
          else:
              return st.warning(f"File not Excel Workbook and .xlsx extention For : {file_name}")
      except Exception as e:
          print(f" read failed for {file_path}: {e}")
          return None               

                    
    # def read_file(file_path, header=None):
    #     try:
    #         lower = file_path.lower()
    #         if lower.endswith(".xlsx"):
    #             return pd.read_excel(file_path, header=header, engine="openpyxl")
    #         if lower.endswith(".xls"):
    #             try:
    #                 return pd.read_excel(file_path, header=header, engine="xlrd")
    #             except Exception:
    #                 return pd.read_excel(file_path, header=header, engine="openpyxl")
    #         # CSV / TXT best-effort
    #         try:
    #             return pd.read_csv(file_path, header=header, sep=None, engine="python",
    #                                on_bad_lines="skip", encoding="utf-8")
    #         except UnicodeDecodeError:
    #             return pd.read_csv(file_path, header=header, sep=None, engine="python",
    #                                on_bad_lines="skip", encoding="windows-1252")
    #     except Exception:
    #         return None

    def to_num(s):
        return pd.to_numeric(s, errors="coerce").fillna(0)

    def normalize_excel_like_date(col):
        num = pd.to_numeric(col, errors="coerce")
        dt_excel = pd.to_datetime(num, unit="D", origin="1899-12-30", errors="coerce")
        dt_fallback = pd.to_datetime(col, errors="coerce", dayfirst=True)
        return dt_excel.combine_first(dt_fallback)

    # For Stock: handle common header variants
    STOCK_PART_COLS = ["PART NO ?", "PART NO", "PART NO.", "PART_NO", "PART NUMBER", "PART_NUMBER"]
    STOCK_QTY_COLS  = ["ON-HAND", "ON HAND", "ONHAND", "ON_HAND", "QTY", "CLOSE_QTY"]

    # ---------- per location ----------
    for i, (brand, dealer, location, location_path) in enumerate(all_locations):
        progress_bar.progress((i + 1) / max(total_locations, 1))
        status_text.text(f"Generating reports for {location} ({i+1}/{total_locations})...")

        BO_LIST = []
        Stock_data = []
        Receving_Pending_Detail = []
        Receving_Today_Detail = []
        Receving_Today_List = []
        Receving_Pending_list = []
        Transfer_List = []
        Transfer_Detail = []

        for file in os.listdir(location_path):
            file_path = os.path.join(location_path, file)
            if not os.path.isfile(file_path):
                continue
           # st.write(file_path)        
            fl = file.lower().strip()

            # BO LIST (header row is the 2nd row -> header=1)
            if fl.startswith("bo list"):
                custom_headers = [
                    'ORDER NO', 'LINE', 'PART NO_ORDER', 'PART NO_CURRENT', 'PART NAME',
                    'PARTSOURCE', 'QUANTITY_ORDER', 'QUANTITY_CURRENT', 'B/O', 'PO DATE',
                    'PDC', 'ETA', 'MSG', 'PROCESSING_ALLOCATION', 'PROCESSING_ON-PICK',
                    'PROCESSING_ON-PACK', 'PROCESSING_PACKED', 'PROCESSING_INVOICE',
                    'PROCESSING_SHIPPEO', 'LOST QTY', 'ELAP'
                ]
                bo_df = read_file(file_path, header=1)
                try:
                    bo_df.columns = custom_headers
                    #[:bo_df.shape[1]]
                except:
                    #bo_df = pd.concat(pd.read_html(file_path, header=1), ignore_index=True)
                    bo_df.columns = custom_headers
                    #[:bo_df.shape[1]]
                bo_df['PO DATE'] = normalize_excel_like_date(bo_df['PO DATE'])
                #st.write(bo_df.head(2))
                if bo_df is None or bo_df.empty:
                    validation_errors.append(f"{location}: Unable to read BO LIST -> {file}")
                    continue
                bo_df.columns = custom_headers
                #[:bo_df.shape[1]]

                required_cols = ['ORDER NO', 'PART NO_CURRENT', 'PO DATE', 'QUANTITY_CURRENT', 'PROCESSING_ALLOCATION']
                missing = [c for c in required_cols if c not in bo_df.columns]
                if missing:
                    validation_errors.append(f"{location}: BO LIST missing columns - {', '.join(missing)}")
                    continue

                bo_df['__source_file__'] = file
                bo_df['Brand'] = brand
                bo_df['Dealer'] = dealer
                bo_df['Location'] = location
                BO_LIST.append(bo_df)
                continue

            # STOCK
            if fl.startswith("stock"):
                sd = read_file(file_path, header=0)
                if sd is None or sd.empty:
                    sd = pd.concat(pd.read_html(file_path, header=0), ignore_index=True)
                    if sd is None or sd.empty:
                        validation_errors.append(f"{location}: Unable to read Stock -> {file}")
                        continue
                sd['Brand'] = brand
                sd['Dealer'] = dealer
                sd['Location'] = location
                sd['__source_file__'] = file
                Stock_data.append(sd)
                

            # RECEIVING PENDING DETAIL (header=1)
            if fl.startswith("receiving pending detail"):
                cols = ['SEQ','CASE NO ','ORDER NO ','LINE NO','PART NO _SUPPLY','PART NO _ORDER','H/K','PART NAME',
                        'SUPPLY QTY','ORDER QTY','ACCEPT QTY','CLAIM QTY','CLAIM TYPE','CLAIM CODE','LOC','LIST PRICE',
                        'NDP (UNIT)','ED (UNIT)','MAT VALUE','DEPOT S/C','VOR S/C','OTHER CHARGES','STAX(%)','CTAX(%)',
                        'ITAX(%)','TAX(%)','HSN CODE','TAX AMT','FRT/INS','SGST AMT','CGST AMT','IGST AMT','COMP CESS AMT',
                        'LANDED COST','ORDER DATE','RECEIVING DATE','STATUS']
                df = read_file(file_path, header=1)
                # if df is None or df.empty:
                #     df = pd.concat(pd.read_html(file_path, header=1), ignore_index=True)
                    
                if df is None or df.empty:
                    validation_errors.append(f"{location}: Unable to read Receiving Pending Detail -> {file}")
                    continue
                df.columns = cols[:df.shape[1]]
                df['ORDER DATE'] = normalize_excel_like_date(df['ORDER DATE'])
                df['__source_file__'] = file
                df['Brand'] = brand
                df['Dealer'] = dealer
                df['Location'] = location
                Receving_Pending_Detail.append(df)
                continue

            # RECEIVING PENDING LIST (header=2)
            if fl.startswith("receiving pending list"):
                cols = ['SEQ','H/K','GR_NO','GR_TYPE','GR_STATUS','INVOICE_NO','INVOICE_DATE','SHIPPED INFORMATION_SUPPLIER',
                        'SHIPPED INFORMATION_TRUCK NO','SHIPPED INFORMATION_CARRIER NAME','SHIPPED INFORMATION_FINISH DATE',
                        'SHIPPED INFORMATION_ACCEPT QTY','SHIPPED INFORMATION_CLAIM QTY','SHIPPED INFORMATION_MAT VALUE',
                        'SHIPPED INFORMATION_FREIGHT AMT','SHIPPED INFORMATION_SGST AMT','SHIPPED INFORMATION_IGST AMT',
                        'SHIPPED INFORMATION_TCS AMT','SHIPPED INFORMATION_TAX AMOUNT']
                df = read_file(file_path, header=2)
                if df is None or df.empty:
                    df = pd.concat(pd.read_html(file_path, header=2), ignore_index=True)
                    if df is None or df.empty:
                        validation_errors.append(f"{location}: Unable to read Receiving Pending List -> {file}")
                        continue
                df.columns = cols[:df.shape[1]]
                df['__source_file__'] = file
                df['Brand'] = brand
                df['Dealer'] = dealer
                df['Location'] = location
                Receving_Pending_list.append(df)
                continue

            # RECEIVING TODAY LIST (header=2)
            if fl.startswith("receiving today list"):
                cols = ['SEQ','H/K','GR_NO','GR_TYPE','GR_STATUS','INVOICE_NO','INVOICE_DATE','SHIPPED INFORMATION_SUPPLIER',
                        'SHIPPED INFORMATION_TRUCK NO','SHIPPED INFORMATION_CARRIER NAME','SHIPPED INFORMATION_FINISH DATE',
                        'SHIPPED INFORMATION_ACCEPT QTY','SHIPPED INFORMATION_CLAIM QTY','SHIPPED INFORMATION_MAT VALUE',
                        'SHIPPED INFORMATION_FREIGHT AMT','SHIPPED INFORMATION_SGST AMT','SHIPPED INFORMATION_IGST AMT',
                        'SHIPPED INFORMATION_TCS AMT','SHIPPED INFORMATION_TAX AMOUNT']
                df = read_file(file_path, header=2)
                if df is  None or  df.empty:
                    df = pd.concat(pd.read_html(file_path, header=2), ignore_index=True)
                    if df is None or df.empty:
                        validation_errors.append(f"{location}: Unable to read Receiving Today List -> {file}")
                        continue
                    df.columns = cols[:df.shape[1]]
                    df['__source_file__'] = file
                    df['Brand'] = brand
                    df['Dealer'] = dealer
                    df['Location'] = location
                    Receving_Today_List.append(df)
                continue

            # RECEIVING TODAY DETAIL (header=1)
            if fl.startswith("receiving today detail"):
                cols = ['SEQ','CASE NO ','ORDER NO ','LINE NO','PART NO _SUPPLY','PART NO _ORDER','H/K','PART NAME',
                        'SUPPLY QTY','ORDER QTY','ACCEPT QTY','CLAIM QTY','CLAIM TYPE','CLAIM CODE','LOC','LIST PRICE',
                        'NDP (UNIT)','ED (UNIT)','MAT VALUE','DEPOT S/C','VOR S/C','OTHER CHARGES','STAX(%)','CTAX(%)',
                        'ITAX(%)','TAX(%)','HSN CODE','TAX AMT','FRT/INS','SGST AMT','CGST AMT','IGST AMT','COMP CESS AMT',
                        'LANDED COST','ORDER DATE','RECEIVING DATE','STATUS']
                df = read_file(file_path, header=1)
                try:
                  df.columns = cols[:df.shape[1]]
                except:
                  df = pd.concat(pd.read_html(file_path, header=1),ignore_index=True)
                  
                if df is not None and not df.empty:
                  #  df.columns = cols[:df.shape[1]]
                    df['__source_file__'] = file
                    df['Brand'] = brand
                    df['Dealer'] = dealer
                    df['Location'] = location
                    Receving_Today_Detail.append(df)
                continue

                # if df is  None or  df.empty:
                #     df = pd.concat(pd.read_html(file_path, header=1), ignore_index=True)
                #     if df is None or df.empty:
                #         validation_errors.append(f"{location}: Unable to read Receiving Today Detail -> {file}")
                #         continue    
                # try:
                #   df.columns = cols[:df.shape[1]]
                #   df['ORDER DATE'] = normalize_excel_like_date(df['ORDER DATE'])
                #   df['__source_file__'] = file
                #   df['Brand'] = brand
                #   df['Dealer'] = dealer
                #   df['Location'] = location
                #   Receving_Today_Detail.append(df)
                # except:
                #   st.write('Recv today details not found')
                #   pass
                # continue

            # TRANSFER LIST (header=1)
            if fl.startswith("transfer list"):
                cols = ['TRANSFER NO','REQ.DATE','REQ.TIME','SEND DATE','SEND.TIME','RECE.DATE','RECE.TIME','REQU.DEALER',
                        'SEND DEALER','ITEM_REQ','ITEM_SEND','QUANTITY_REQ','QUANTITY_SEND','AMOUNT','AMOUNT2','TAXABLE AMT',
                        'SGST AMT','CGST AMT','IGST AMT','COMP CESS AMT','STATUS']
                df = read_file(file_path, header=1)
                if df is  None or  df.empty:
                    df = pd.concat(pd.read_html(file_path, header=1), ignore_index=True)
                    if df is None or df.empty:
                        validation_errors.append(f"{location}: Unable to read Transfer List -> {file}")
                        continue
                    df.columns = cols[:df.shape[1]]
                    df['__source_file__'] = file
                    df['Brand'] = brand
                    df['Dealer'] = dealer
                    df['Location'] = location
                    Transfer_List.append(df)
                continue

            # TRANSFER DETAIL (header=0)
            if fl.startswith("transfer detail"):
                df = read_file(file_path, header=0)
                if df is  None or  df.empty:
                    df = pd.concat(pd.read_html(file_path, header=0), ignore_index=True)
                    if df is None or df.empty:
                        validation_errors.append(f"{location}: Unable to read Transfer Detail -> {file}")
                        continue
                if df is not None and not df.empty:
                  df['__source_file__'] = file
                  df['Brand'] = brand
                  df['Dealer'] = dealer
                  df['Location'] = location
                  Transfer_Detail.append(df)
                else:
                    st.warning(f"{location}: Transfer Detail is empty -> {file}")  
                #continue

      
        # ---------- REPORT GEN ----------
        frames_for_oem = []

        # BO LIST â†’ last 90 days; compute transit/T/F/Remark
        if BO_LIST:
            oem = pd.concat(BO_LIST, ignore_index=True)
            # Date parse (supports 2-digit/4-digit year strings)
            oem['PO DATE'] = pd.to_datetime(oem['PO DATE'], errors='coerce')
            cutoff_90 = (datetime.today() - timedelta(days=90)).date()
            oem_work = oem[oem['PO DATE'].dt.date >= cutoff_90].copy()

            # numerics
            for c in ['B/O', 'PROCESSING_ALLOCATION', 'PROCESSING_ON-PICK', 'PROCESSING_ON-PACK',
                      'PROCESSING_PACKED', 'PROCESSING_INVOICE', 'PROCESSING_SHIPPEO', 'QUANTITY_CURRENT']:
                if c in oem_work.columns:
                    oem_work[c] = to_num(oem_work[c])

            oem_work['transit'] = (
                oem_work.get('B/O', 0)
                + oem_work.get('PROCESSING_ALLOCATION', 0)
                + oem_work.get('PROCESSING_ON-PICK', 0)
                + oem_work.get('PROCESSING_ON-PACK', 0)
                + oem_work.get('PROCESSING_PACKED', 0)
                + oem_work.get('PROCESSING_INVOICE', 0)
            )
            oem_work['T/F'] = oem_work.get('QUANTITY_CURRENT', 0).eq(oem_work.get('PROCESSING_SHIPPEO', 0))

            def _remark(r):
                if r['transit'] == 0.0 and bool(r['T/F']) is True:
                    return 'Ok'
                if r['transit'] > 0.0 and bool(r['T/F']) is False:
                    return 'Ok'
                if r['transit'] == 0.0 and bool(r['T/F']) is False:
                    return 'Pls Check'
                return None

            oem_work['Remark'] = oem_work.apply(_remark, axis=1)
            oem_work['transit'] = oem_work.apply(lambda row:row['QUANTITY_CURRENT'] if row['Remark']=='Pls Check' else row['transit'] ,axis=1)
            oem_workf = oem_work[['Brand', 'Dealer', 'Location', 'ORDER NO', 'PART NO_CURRENT', 'PO DATE', 'transit', 'Remark']].copy()
            oem_workf.rename(columns={
                'ORDER NO': 'OrderNumber',
                'PART NO_CURRENT': 'PartNumber',
                'PO DATE': 'OrderDate',
                'transit': 'POQty'
            }, inplace=True)
            frames_for_oem.append(oem_workf)

        # Receiving Pending Detail â†’ last 60 days
        if Receving_Pending_Detail:
            rpd = pd.concat(Receving_Pending_Detail, ignore_index=True)
            rpd['ORDER DATE'] = pd.to_datetime(rpd['ORDER DATE'], errors='coerce')
            cutoff_60 = (datetime.today() - timedelta(days=60)).date()
            rpdw = rpd[rpd['ORDER DATE'].dt.date >= cutoff_60].copy()
            rpdw = rpdw[['Brand', 'Dealer', 'Location', 'ORDER NO ', 'PART NO _SUPPLY', 'ORDER DATE', 'ACCEPT QTY', '__source_file__']]
            rpdw.rename(columns={
                'ORDER NO ': 'OrderNumber',
                'PART NO _SUPPLY': 'PartNumber',
                'ORDER DATE': 'OrderDate',
                'ACCEPT QTY': 'POQty',
                '__source_file__': 'Remark'
            }, inplace=True)
            frames_for_oem.append(rpdw)

        # Receiving Today Detail â†’ last 60 days
        if Receving_Today_Detail:
            rtd = pd.concat(Receving_Today_Detail, ignore_index=True)
            rtd['ORDER DATE'] = pd.to_datetime(rtd['ORDER DATE'], errors='coerce')
            cutoff_60 = (datetime.today() - timedelta(days=60)).date()
            rtdw = rtd[rtd['ORDER DATE'].dt.date >= cutoff_60].copy()
            rtdw = rtdw[['Brand', 'Dealer', 'Location', 'ORDER NO ', 'PART NO _SUPPLY', 'ORDER DATE', 'ACCEPT QTY', '__source_file__']]
            rtdw.rename(columns={
                'ORDER NO ': 'OrderNumber',
                'PART NO _SUPPLY': 'PartNumber',
                'ORDER DATE': 'OrderDate',
                'ACCEPT QTY': 'POQty',
                '__source_file__': 'Remark'
            }, inplace=True)
            frames_for_oem.append(rtdw)

        # Save OEM_{...}.xlsx (Hyundai unified)
        # if frames_for_oem:
        #     key_oem = f"OEM_{brand}_{dealer}_{location}.xlsx"
        #     oem_final = pd.concat(frames_for_oem, ignore_index=True)
        #     oem_final['PartNumber']  = oem_final['PartNumber'].astype(str).str.strip().replace('-','').replace('.','')
            
        #     oem_final['OEMInvoiceNo']=''
        #     oem_final['OEMInvoiceDate']=''
        #     oem_final['OEMInvoiceQty']=''
        #     oem_final['OrderDate'] = pd.to_datetime(oem_final['OrderDate'], errors='coerce')
        #     oem_final['OrderDate'] = oem_final['OrderDate'].dt.strftime('%d %b %Y')
        #     oem_c = oem_final[oem_final['Remark']=='Pls Check'][['Location','OrderNumber']].drop_duplicates()
        #     # Preview for UI & for dealerwise ZIP
        #     previews[key_oem] = oem_final.copy()

        #     # Build Excel with two sheets (sheet1: summary of "Pls Check", sheet2: full)
        #     excel_buffer = io.BytesIO()
        #     with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
        #         #oem_c = oem_final[oem_final['Remark']=='Pls Check'][['Location','OrderNumber']].drop_duplicates()
        #         oem_c.reset_index(drop=True).to_excel(writer, sheet_name='sheet1', index=False)
        #         oem_final.reset_index(drop=True).to_excel(writer, sheet_name='sheet2', index=False)
        #     files[key_oem] = excel_buffer.getvalue()

        # Save OEM_{...}.xlsx (Hyundai unified)
        if frames_for_oem:
            key_oem = f"OEM_{brand}_{dealer}_{location}.xlsx"
            oem_final = pd.concat(frames_for_oem, ignore_index=True)
        
            # CLEAN: remove - and . safely
            oem_final['PartNumber'] = (
                oem_final['PartNumber'].astype(str).str.strip().str.replace(r'[\-.]', '', regex=True)
            )
        
            oem_final['OEMInvoiceNo'] = ''
            oem_final['OEMInvoiceDate'] = ''
            oem_final['OEMInvoiceQty'] = ''
            oem_final['OrderDate'] = pd.to_datetime(oem_final['OrderDate'], errors='coerce').dt.strftime('%d %b %Y')
        
            # Preview for UI & for dealerwise ZIP
            previews[key_oem] = oem_final.copy()
        
            # Build Excel with two sheets: Summary (Pls Check) + FullData
            excel_buffer = io.BytesIO()
            with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                summary = (
                    oem_final.loc[oem_final['Remark'].astype(str).str.strip().str.lower().eq('pls check'),
                                  ['Location', 'OrderNumber']]
                            .drop_duplicates()
                )
                # keep a visible row even if empty (optional)
                if summary.empty:
                    summary = pd.DataFrame([{'Location': 'â€”', 'OrderNumber': 'No "Pls Check" rows'}])
        
                summary.to_excel(writer, sheet_name='Check Order status', index=False)
                oem_final.reset_index(drop=True).to_excel(writer, sheet_name='sheet1', index=False)
        
                # make Summary the active sheet
                writer.book.active = 0
        
            files[key_oem] = excel_buffer.getvalue()

        
        # Save Stock_{...}.xlsx
        if Stock_data:
            key_stock = f"Stock_{brand}_{dealer}_{location}.xlsx"
            stock_df = pd.concat(Stock_data, ignore_index=True)
            #stock_df['PART NO ?']  = stock_df['PART NO ?'].astype(str).str.strip().replace('.','').replace('-','')
            stock_df['PART NO ?'] = (stock_df['PART NO ?'].astype(str).str.strip().str.replace('.', '', regex=False).str.replace('-', '', regex=False))
            stock_df['PART TYPE'] = stock_df['PART TYPE'].astype(str).str.strip()
            if select_categories == ['Spares']:
                stock_df = stock_df[stock_df['PART TYPE'].isin(['X', 'Y'])]
            elif select_categories == ['Accessories']:
                stock_df = stock_df[stock_df['PART TYPE'] == 'A']
            elif set(select_categories) == {'Spares', 'Accessories'}:
                stock_df = stock_df[stock_df['PART TYPE'].isin(['X', 'Y', 'A'])]

            # Final selection
            stock_final = stock_df[['Brand', 'Dealer', 'Location', 'PART NO ?', 'ON-HAND']].rename(
                columns={'PART NO ?': 'Partnumber', 'ON-HAND': 'Qty'}
            )
            previews[key_stock] = stock_final.copy()
            buf = io.BytesIO()
            with pd.ExcelWriter(buf, engine="openpyxl") as writer:
                stock_final.to_excel(writer, index=False, sheet_name="Sheet1")
            files[key_stock] = buf.getvalue()

        # Pending (from Transfer_Detail minimal subset) -> Pending_{...}.xlsx
        if Transfer_Detail:
            tr = pd.concat(Transfer_Detail, ignore_index=True)
            # Only add if expected columns exist
            needed_cols = {'PART NO ?', 'QUANTITY'}
            if needed_cols.issubset(set(tr.columns)):
                tr_Df = tr[['Brand','Dealer','Location','PART NO ?','QUANTITY']].copy()
                tr_Df['PART NO ?'] = tr_Df['PART NO ?'].astype(str).str.strip()
                tr_Df.rename(columns={'PART NO ?':'PartNumber','QUANTITY':'Qty'}, inplace=True)
                key_pending = f"Pending_{brand}_{dealer}_{location}.xlsx"
                previews[key_pending] = tr_Df.copy()
                buf = io.BytesIO()
                with pd.ExcelWriter(buf, engine="openpyxl") as writer:
                    tr_Df.to_excel(writer, index=False, sheet_name="Sheet1")
                files[key_pending] = buf.getvalue()

    # ---------- UI ----------
    if validation_errors:
        st.warning("âš  Validation issues found:")
        for error in validation_errors:
            st.write(f"- {error}")

    st.success("ðŸŽ‰ Reports generated successfully!")
    st.subheader("ðŸ“¥ Download Reports")

    # Build sections from available file names (files dict is source of truth for downloads)
    report_types = {
        'OEM':      [k for k in files.keys() if k.startswith('OEM_')],
        'Stock':    [k for k in files.keys() if k.startswith('Stock_')],
        'Transfer': [k for k in files.keys() if k.startswith(('Transfer_','Pending_'))],
    }

    for report_type, names in report_types.items():
        if not names:
            continue
        with st.expander(f"ðŸ“‚ {report_type} Reports ({len(names)})", expanded=False):
            for name in names:
                st.markdown(f"### ðŸ“„ {name}")

                # Show preview if we have it
                df_preview = previews.get(name)
                if df_preview is not None and not df_preview.empty:
                    st.dataframe(df_preview.head(5))
                else:
                    st.info("No preview available.")

                # Download button (bytes)
                blob = files.get(name)
                if blob:
                    st.download_button(
                        label="â¬‡ Download Excel",
                        data=blob,
                        file_name=name,
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        key=f"dl_{name}",
                    )
                else:
                    st.warning("âš  Download content missing for this file.")

    # ---------- Combined ZIP per (report_type, brand, dealer) using previews (DataFrames) ----------
    # grouped_data = defaultdict(list)
    # for file_name, df in previews.items():
    #     if df is None or df.empty:
    #         continue
    #     parts = file_name.replace(".xlsx", "").split("_")
    #     if len(parts) >= 4:
    #         rep, br, dlr = parts[0], parts[1], parts[2]
    #         loc_part = "_".join(parts[3:])
    #         if "Location" not in df.columns:
    #             df = df.copy()
    #             df["Location"] = loc_part
    #         grouped_data[(rep, br, dlr)].append(df)
    #     else:
    #         st.warning(f"â— Invalid file name format: {file_name}")

    # if grouped_data:
    #     zip_buffer = io.BytesIO()
    #     with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zipf:
    #         for (rep, br, dlr), df_list in grouped_data.items():
    #             combined_df = pd.concat(df_list, ignore_index=True)
    #             excel_buffer = io.BytesIO()
    #             with pd.ExcelWriter(excel_buffer, engine="openpyxl") as writer:
    #                 combined_df.to_excel(writer, sheet_name="Sheet1", index=False)
    #             output_filename = f"{rep}_{br}_{dlr}.xlsx"
    #             zipf.writestr(output_filename, excel_buffer.getvalue())

    #     st.download_button(
    #         label="ðŸ“¦ Download Combined Dealer Reports ZIP",
    #         data=zip_buffer.getvalue(),
    #         file_name="Combined_Dealerwise_Reports.zip",
    #         mime="application/zip",
    #     )
    # else:
    #     st.info("â„¹ No reports available to download.")
    #     st.warring("Pls check Folder Structure")
    # ---------- Combined ZIP per (report_type, brand, dealer) using previews (DataFrames) ----------
    grouped_data = defaultdict(list)
    for file_name, df in previews.items():
        if df is None or df.empty:
            continue
        parts = file_name.replace(".xlsx", "").split("_")
        if len(parts) >= 4:
            rep, br, dlr = parts[0], parts[1], parts[2]
            loc_part = "_".join(parts[3:])
            if "Location" not in df.columns:
                df = df.copy()
                df["Location"] = loc_part
            grouped_data[(rep, br, dlr)].append(df)
        else:
            st.warning(f"â— Invalid file name format: {file_name}")
    
    if grouped_data:
        zip_buffer = io.BytesIO()
        with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zipf:
            for (rep, br, dlr), df_list in grouped_data.items():
                combined_df = pd.concat(df_list, ignore_index=True)
    
                excel_buffer = io.BytesIO()
                with pd.ExcelWriter(excel_buffer, engine="openpyxl") as writer:
                    if rep == "OEM":
                        summary = (
                            combined_df.loc[combined_df['Remark'].astype(str).str.strip().str.lower().eq('pls check'),
                                            ['Location', 'OrderNumber']]
                                       .drop_duplicates()
                        )
                        if summary.empty:
                            summary = pd.DataFrame([{'Location': 'â€”', 'OrderNumber': 'No "Pls Check" rows'}])
    
                        summary.to_excel(writer, sheet_name="Check Order status", index=False)
                        combined_df.to_excel(writer, sheet_name="sheet1", index=False)
                        writer.book.active = 0
                    else:
                        combined_df.to_excel(writer, sheet_name="Sheet1", index=False)
    
                output_filename = f"{rep}_{br}_{dlr}.xlsx"
                zipf.writestr(output_filename, excel_buffer.getvalue())
    
        st.download_button(
            label="ðŸ“¦ Download Combined Dealer Reports ZIP",
            data=zip_buffer.getvalue(),
            file_name="Combined_Dealerwise_Reports.zip",
            mime="application/zip",
        )
    else:
        st.info("â„¹ No reports available to download.")
        st.warning("Pls check Folder Structure")  # (fix typo from st.warring -> st.warning)


























